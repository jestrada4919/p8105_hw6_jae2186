HW6: Linear Models
================
UNI: jae2186 (Jennifer Estrada)
12/6/2021

## Problem 1: Understanding factors effecting birthweight

### Data Introduction

Given data provided for 4000 children, the following code will runs a
regression analysis with several variables against birth weight. I will
be focusing on a select number of variables and employ a regression
analysis to assess how they impact birth weight; similarly, certain
measurements of the child will also be included to see if and how they
may correlate to birth weight. The selected variables of interest
include:

-   measurements and demographics taken of the child at birth -
    -   sex (either male or female),
    -   head circumference (in cm),
    -   length (in cm),
    -   birth weight (in gm), and
    -   gestational age (in weeks);
-   measurements and demographics taken of mother or family at birth -
    -   the family’s monthly income (rounded to nearest hundred of
        dollars),
    -   the mother’s pre-pregnancy BMI,
    -   average number of cigarettes smoked by the mother per day during
        pregnancy, and
    -   the mother’s age at delivery in years.

``` r
df <-
  read_csv("./data/birthweight.csv") %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         mrace = as.factor(mrace), 
         malform = as.factor(malform)) %>% 
  select(-pnumlbw, -pnumsga)
```

(Note: Certain variables were removed from the data set because it was
noted there were no differences in this variable across the data set -
i.e. there were no mothers who reported a having previous low birth
weight babies (`pnumlbw`) nor prior small for gestational age babies
(`pnumsga`).

### Setting up primary model

First I will use a piecewise linear regression to assess gestational age
in weeks (`gaweeks`) as a lone predictor of birth weight (`bwt`) with a
changepoint at 35 weeks for gestational age. The resulting plot with the
model as well as a plot of residuals against the fitted values is shown
below.

``` r
df <- 
  df %>% 
  mutate(weight_gaweeks = (gaweeks > 35) * (gaweeks - 35))

model_1_pwl <- lm(bwt ~ gaweeks + weight_gaweeks, data = df)

model_plot <-
  df %>% 
  add_predictions(model_1_pwl) %>% 
  ggplot(aes(x = gaweeks, y = bwt)) + 
  geom_point(alpha = .3) +
  geom_line(aes(y = pred), color = "red") +
  labs(
    x = "Gestational Age (weeks)",
    y = "Child Birth Weight (grams)")

resid_plot <-
  df %>% 
  add_predictions(model_1_pwl) %>% 
  add_residuals(model_1_pwl) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .3) +
  labs(
    x = "Fitted Values",
    y = "Residuals")

model_plot + resid_plot
```

<img src="p8105_hw6_jae2186_files/figure-gfm/model_1_pwl-1.png" width="90%" />

### Setting up comparison models

The following two models will be compared to the one used above. The
first one will use length at birth and gestational age as predictors but
will only look at the main effect and not the individual interactions.
The second one uses head circumference, length, and sex as predicts
keeping in consideration all of their interactions as well (both two-
and three-way interactions). In both cases a linear model will be
applied.

``` r
model_2_lm <-
  lm(bwt ~ blength + gaweeks, data = df)

model_3_lm <-
  lm(bwt ~ blength * bhead * babysex + blength * bhead + 
       blength * babysex + bhead * babysex, data = df)
```

The following code chunk will use cross validation and the resulting
prediction error to compare the three different models.

``` r
cv_df <- 
  crossv_mc(df, 100)

cv_df <-
  cv_df %>%  
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df <-
  cv_df %>% 
  mutate(
    model_1 = map(.x = train, ~lm(bwt ~ gaweeks + weight_gaweeks, data = .x)),
    model_2 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
    model_3 = map(.x = train, ~lm(bwt ~ blength * bhead * babysex + blength * bhead + 
       blength * babysex + bhead * babysex, data = .x))
    ) %>% 
  mutate(
    rmse_1 = map2_dbl(.x = model_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(.x = model_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(.x = model_3, .y = test, ~rmse(model = .x, data = .y))
  )

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>%   
  ggplot(aes(x = model, y = rmse, fill = model, alpha = 0.5)) + 
  geom_violin() +
  labs(
    title = "Comparison of models",
    x = "Model",
    y = "Root-mean-square error, RMSE") +
  theme(legend.position = "none")
```

<img src="p8105_hw6_jae2186_files/figure-gfm/unnamed-chunk-1-1.png" width="90%" />

As noted, the two models used for comparison fit the data better based
solely on the resulting RSME values. The primary piecewise linear model
had notably higher RSMEs; however, considering that this model only
considered one predictor of birth weight it is not surprising that it
did not fit the data as well as models built around the interactions of
at least 2 variables. When considering the interactions of 3 different
predictors as in model 3, the error and fit of the model is improved
compared to model 2 which only looks at the main interaction of 2
predictors.
